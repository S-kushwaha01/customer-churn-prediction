# Customer Churn Prediction using Machine Learning

## ğŸ“ŒProject Overview
Customer churn refers to customers who stop using a companyâ€™s service.  
In this project, we build a machine learning model to predict customer churn using historical customer data from a telecom company.

The goal is to identify customers who are likely to leave, so businesses can take preventive actions such as discounts, better support, or personalized offers.

## ğŸ¯ Problem Statement
Telecom companies lose revenue when customers churn.  
This project aims to:  
- Analyze customer behavior
- Identify factors contributing to churn
- Build ML models to predict churn accurately

 
## ğŸ“‚ Dataset Description
Dataset: IBM Telco Customer Churn Dataset   
- Total Records: 7,043 customers  
- Total Features: 21  
- Target Variable: Churn (Yes = customer left, No = customer stayed)  

Key Features:  
- `tenure` â€“ Number of months customer stayed  
- `MonthlyCharges` â€“ Monthly bill amount  
- `TotalCharges` â€“ Total amount charged  
- `Contract` â€“ Contract type  
- `PaymentMethod` â€“ Payment method  
- `InternetService` â€“ Internet service type

## ğŸ” Exploratory Data Analysis (EDA) â€“ Key Insights
- Dataset is **imbalanced**, reflecting real-world customer behavior
- Customers with low `tenure` are more likely to churn
- Higher `MonthlyCharges` increase churn risk
- `Month-to-month` contracts have the highest churn rate
- Customers using `Electronic check` payment method churn more
- `Long-term contracts` significantly reduce churn


## âš™ï¸ Data Preprocessing & Feature Engineering
- Converted `TotalCharges` to numeric format
- Handled missing values using **median imputation**
- Encoded categorical variables using **One-Hot Encoding**
- Split data into training and testing sets (**80/20**)
- Applied **feature scaling** where required

---

## âš–ï¸ Class Imbalance Handling
Instead of applying a single global resampling method, class imbalance was handled **individually for each model** using model-specific techniques, such as:
- `Class weight` adjustment
- `Decision threshold` tuning
- `Model-internal` imbalance handling

This approach resulted in **better and more stable performance** compared to applying **SMOTE globally**.


## ğŸ¤– Machine Learning Models Used
- `Logistic Regression` â€“ Baseline model
- `Support Vector Machine (SVM)`
- `XGBoost Classifier`

---

## ğŸ“Š Evaluation Metrics
- `Accuracy`
- `Precision`
- `Recall` *(primary metric)*
- `F1 Score`


## ğŸ“ˆ Model Comparison Summary

- `Logistic Regression` provided the most **balanced and interpretable** performance, delivering strong `Recall` with stable `Precision` and consistent overall behavior.

- `Support Vector Machine (SVM)` achieved higher `Recall` under aggressive tuning but suffered from reduced `Precision` and lower stability, making it less suitable as the final production model.

- `XGBoost` delivered **competitive performance** with a strong balance between `Recall` and `F1 Score`, positioning it as a robust tree-based alternative aligned with industry practices.

ğŸ“Œ **Recall** was prioritized to minimize missed churn customers, as **false negatives directly impact business revenue**.  
However, final model selection emphasized a **balanced trade-off between recall, precision, and model stability**, rather than optimizing recall alone.


## âœ… Final Model Selection
Based on model performance, stability, and interpretability, **Logistic Regression** was selected as the final balanced model for churn prediction.  

While XGBoost demonstrated competitive performance, Logistic Regression provided a better trade-off between recall, precision, and explainability, making it more suitable for real-world deployment and business decision-making.


## ğŸ’¼ Business Impact

The final model enables proactive identification of high-risk customers, allowing businesses to:
- Launch targeted retention campaigns
- Reduce revenue loss due to churn
- Improve customer lifetime value
- Optimize marketing and support costs





